{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "011d04c6",
   "metadata": {},
   "source": [
    "# 4.4 模型选择、欠拟合和过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0212d7",
   "metadata": {},
   "source": [
    "将模型在训练数据上拟合的比在潜在分布中更接近的现象称为过拟合（overfitting）， 用于对抗过拟合的技术称为正则化（regularization）。 在前面的章节中，有些读者可能在用Fashion-MNIST数据集做实验时已经观察到了这种过拟合现象。 在实验中调整模型架构或超参数时会发现： 如果有足够多的神经元、层数和训练迭代周期， 模型最终可以在训练集上达到完美的精度，此时测试集的准确性却下降"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0feab07",
   "metadata": {},
   "source": [
    "## 4.4.1 训练误差和泛化误差"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47ea281",
   "metadata": {},
   "source": [
    "为了进一步讨论这一现象，我们需要了解训练误差和泛化误差。 训练误差（training error）是指， 模型在训练数据集上计算得到的误差。 泛化误差（generalization error）是指， 模型应用在同样从原始样本的分布中抽取的无限多数据样本时，模型误差的期望。\n",
    "\n",
    "问题是，我们永远不能准确地计算出泛化误差。 这是因为无限多的数据样本是一个虚构的对象。 在实际中，我们只能通过将模型应用于一个独立的测试集来估计泛化误差， 该测试集由随机选取的、未曾在训练集中出现的数据样本构成。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9130a121",
   "metadata": {},
   "source": [
    "当我们训练模型时，我们试图找到一个能够尽可能拟合训练数据的函数。 但是如果它执行地“太好了”，而不能对看不见的数据做到很好泛化，就会导致过拟合。 这种情况正是我们想要避免或控制的。 深度学习中有许多启发式的技术旨在防止过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3154f20f",
   "metadata": {},
   "source": [
    "### 4.4.1.1 统计学习理论"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03b4a5c",
   "metadata": {},
   "source": [
    "### 4.4.1.2 模型复杂性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8632eac0",
   "metadata": {},
   "source": [
    "当我们有简单的模型和大量的数据时，我们期望泛化误差与训练误差相近。 当我们有更复杂的模型和更少的样本时，我们预计训练误差会下降，但泛化误差会增大。 模型复杂性由什么构成是一个复杂的问题。 一个模型是否能很好地泛化取决于很多因素。 例如，具有更多参数的模型可能被认为更复杂， 参数有更大取值范围的模型可能更为复杂。 通常对于神经网络，我们认为需要更多训练迭代的模型比较复杂， 而需要早停（early stopping）的模型（即较少训练迭代周期）就不那么复杂。\n",
    "\n",
    "我们很难比较本质上不同大类的模型之间（例如，决策树与神经网络）的复杂性。 就目前而言，一条简单的经验法则相当有用： 统计学家认为，能够轻松解释任意事实的模型是复杂的， 而表达能力有限但仍能很好地解释数据的模型可能更有现实用途。 在哲学上，这与波普尔的科学理论的可证伪性标准密切相关： 如果一个理论能拟合数据，且有具体的测试可以用来证明它是错误的，那么它就是好的。   \n",
    "\n",
    "重点介绍几个倾向于影响模型泛化的因素。\n",
    "1. 可调整参数的数量。当可调整参数的数量（有时称为自由度）很大时，模型往往更容易过拟合。\n",
    "2. 参数采用的值。当权重的取值范围较大时，模型可能更容易过拟合。\n",
    "3. 训练样本的数量。即使模型很简单，也很容易过拟合只包含一两个样本的数据集。而过拟合一个有数百万个样本的数据集则需要一个极其灵活的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7607a00",
   "metadata": {},
   "source": [
    "## 4.4.2 模型选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e70209e",
   "metadata": {},
   "source": [
    "在机器学习中，我们通常在评估几个候选模型后选择最终的模型。 这个过程叫做模型选择。 有时，需要进行比较的模型在本质上是完全不同的（比如，决策树与线性模型）。 又有时，我们需要比较不同的超参数设置下的同一类模型。\n",
    "\n",
    "例如，训练多层感知机模型时，我们可能希望比较具有 不同数量的隐藏层、不同数量的隐藏单元以及不同的激活函数组合的模型。 为了确定候选模型中的最佳模型，我们通常会使用验证集。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5315dc96",
   "metadata": {},
   "source": [
    "### 4.4.2.1 验证集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c398a7",
   "metadata": {},
   "source": [
    "原则上，在我们确定所有的超参数之前，我们不希望用到测试集。 如果我们在模型选择过程中使用测试数据，可能会有过拟合测试数据的风险，那就麻烦大了。 如果我们过拟合了训练数据，还可以在测试数据上的评估来判断过拟合。 但是如果我们过拟合了测试数据，我们又该怎么知道呢？\n",
    "\n",
    "因此，我们决不能依靠测试数据进行模型选择。 然而，我们也不能仅仅依靠训练数据来选择模型，因为我们无法估计训练数据的泛化误差。\n",
    "\n",
    "在实际应用中，情况变得更加复杂。 虽然理想情况下我们只会使用测试数据一次， 以评估最好的模型或比较一些模型效果，但现实是测试数据很少在使用一次后被丢弃。 我们很少能有充足的数据来对每一轮实验采用全新测试集。\n",
    "\n",
    "解决此问题的**常见做法是将我们的数据分成三份**， 除了训练和测试数据集之外，还增加一个验证数据集（validation dataset）， 也叫验证集（validation set）。 但现实是验证数据和测试数据之间的边界模糊得令人担忧。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c661a5",
   "metadata": {},
   "source": [
    "### 4.2.2.2 K折交叉验证\n",
    "\n",
    "1. **数据划分**：将数据集分成 K 个大小相等的子集（折）。\n",
    "2. **循环训练**：每次用 K-1 个子集训练模型，剩下的 1 个子集用于测试，重复 K 次。\n",
    "3. **性能评估**：将 K 次测试的性能（如准确率）平均，得到模型的总体表现。\n",
    "4. **优点**：充分利用数据，减少过拟合风险，结果更可靠。\n",
    "5. **常见选择**：K 通常取 5 或 10，取决于数据集大小。\n",
    "\n",
    "简单来说，K 折交叉验证是一种评估模型稳定性和准确性的方法，通过多次训练和测试来降低偏差。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4998702",
   "metadata": {},
   "source": [
    "## 4.4.3 欠拟合还是过拟合\n",
    "欠拟合（Underfitting）\n",
    "- 定义：模型在训练集上的误差仍然很高，说明模型尚未学习到数据中的模式。\n",
    "- 常见原因：\n",
    "    - 模型容量太小（比如参数太少）\n",
    "    - 训练时间不够\n",
    "    - 过强的正则化ß\n",
    "- 现象：\n",
    "    - 训练误差和测试误差都很高\n",
    "    - 损失曲线下降缓慢，甚至不下降\n",
    "\n",
    "过拟合（Overfitting）\n",
    "- 定义：模型在训练集上表现很好，但在测试集上误差很高，说明模型“记住了”训练数据而不是“学习”了数据的普遍规律。\n",
    "- 常见原因：\n",
    "    - 模型太复杂（例如层数太多，参数过多）\n",
    "    - 训练太久导致记住训练集\n",
    "    - 训练数据太少或有噪声\n",
    "- 现象：\n",
    "    - 训练误差持续下降，而测试误差开始上升\n",
    "    - 损失曲线“分叉”：训练集和测试集的表现差距越来越大\n",
    "\n",
    "当我们的训练误差明显低于验证误差时要小心， 这表明严重的过拟合（overfitting）。 注意，过拟合并不总是一件坏事。 特别是在深度学习领域，众所周知， 最好的预测模型在训练数据上的表现往往比在保留（验证）数据上好得多。 最终，我们通常更关心验证误差，而不是训练误差和验证误差之间的差距。\n",
    "\n",
    "判断是否出现过拟合:     \n",
    "看 loss 曲线, 训练 loss 一直下降，测试 loss 先下降后上升   \n",
    "看准确率, 训练集接近 100%，验证集不升反降   \n",
    "加数据, 新数据一来表现急剧变差，说明模型太依赖训练集了   \n",
    "交叉验证, 多折交叉验证能发现模型是否稳定泛化   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1f3a20",
   "metadata": {},
   "source": [
    "## 4.4.4 多项式回归\n",
    "我们现在可以通过多项式拟合来探索这些概念。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d61066e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ddcf43",
   "metadata": {},
   "source": [
    "### 4.4.4.1. 生成数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89ba0681",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_degree = 20  # 多项式的最大阶数\n",
    "n_train, n_test = 100, 100  # 训练和测试数据集大小\n",
    "true_w = np.zeros(max_degree)  # 分配大量的空间\n",
    "true_w[0:4] = np.array([5, 1.2, -3.4, 5.6])\n",
    "\n",
    "features = np.random.normal(size=(n_train + n_test, 1))\n",
    "np.random.shuffle(features)\n",
    "poly_features = np.power(features, np.arange(max_degree).reshape(1, -1))\n",
    "for i in range(max_degree):\n",
    "    poly_features[:, i] /= math.gamma(i + 1)  # gamma(n)=(n-1)!\n",
    "# labels的维度:(n_train+n_test,)\n",
    "labels = np.dot(poly_features, true_w)\n",
    "labels += np.random.normal(scale=0.1, size=labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf803b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.9847],\n",
       "         [ 0.2037]]),\n",
       " tensor([[ 1.0000e+00, -9.8467e-01,  4.8479e-01, -1.5912e-01,  3.9170e-02,\n",
       "          -7.7138e-03,  1.2659e-03, -1.7807e-04,  2.1918e-05, -2.3980e-06,\n",
       "           2.3612e-07, -2.1136e-08,  1.7344e-09, -1.3137e-10,  9.2395e-12,\n",
       "          -6.0652e-13,  3.7327e-14, -2.1620e-15,  1.1827e-16, -6.1293e-18],\n",
       "         [ 1.0000e+00,  2.0365e-01,  2.0737e-02,  1.4077e-03,  7.1668e-05,\n",
       "           2.9191e-06,  9.9078e-08,  2.8825e-09,  7.3376e-11,  1.6603e-12,\n",
       "           3.3813e-14,  6.2600e-16,  1.0624e-17,  1.6643e-19,  2.4209e-21,\n",
       "           3.2868e-23,  4.1834e-25,  5.0115e-27,  5.6700e-29,  6.0773e-31]]),\n",
       " tensor([1.2839, 5.3167]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy ndarray转换为tensor\n",
    "true_w, features, poly_features, labels = [torch.tensor(x, dtype=\n",
    "    torch.float32) for x in [true_w, features, poly_features, labels]]\n",
    "\n",
    "features[:2], poly_features[:2, :], labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccbeab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(net, data_iter, loss):  #@save\n",
    "    \"\"\"评估给定数据集上模型的损失\"\"\"\n",
    "    metric = d2l.Accumulator(2)  # 损失的总和,样本数量\n",
    "    for X, y in data_iter:\n",
    "        out = net(X)\n",
    "        y = y.reshape(out.shape)\n",
    "        l = loss(out, y)\n",
    "        metric.add(l.sum(), l.numel())\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13854efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_features, test_features, train_labels, test_labels,\n",
    "          num_epochs=400):\n",
    "    loss = nn.MSELoss(reduction='none')\n",
    "    input_shape = train_features.shape[-1]\n",
    "    # 不设置偏置，因为我们已经在多项式中实现了它\n",
    "    net = nn.Sequential(nn.Linear(input_shape, 1, bias=False))\n",
    "    batch_size = min(10, train_labels.shape[0])\n",
    "    train_iter = d2l.load_array((train_features, train_labels.reshape(-1,1)),\n",
    "                                batch_size)\n",
    "    test_iter = d2l.load_array((test_features, test_labels.reshape(-1,1)),\n",
    "                               batch_size, is_train=False)\n",
    "    trainer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss', yscale='log',\n",
    "                            xlim=[1, num_epochs], ylim=[1e-3, 1e2],\n",
    "                            legend=['train', 'test'])\n",
    "    for epoch in range(num_epochs):\n",
    "        d2l.train_epoch_ch3(net, train_iter, loss, trainer)\n",
    "        if epoch == 0 or (epoch + 1) % 20 == 0:\n",
    "            animator.add(epoch + 1, (evaluate_loss(net, train_iter, loss),\n",
    "                                     evaluate_loss(net, test_iter, loss)))\n",
    "    print('weight:', net[0].weight.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37b687a",
   "metadata": {},
   "source": [
    "### 4.4.4.2 三阶多项式函数拟合 (正常)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317faf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从多项式特征中选择前4个维度，即1,x,x^2/2!,x^3/3!\n",
    "train(poly_features[:n_train, :4], poly_features[n_train:, :4],\n",
    "      labels[:n_train], labels[n_train:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b085a32",
   "metadata": {},
   "source": [
    "### 4.4.4.3 线性函数拟合 (欠拟合)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b316bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从多项式特征中选择前2个维度，即1和x\n",
    "train(poly_features[:n_train, :2], poly_features[n_train:, :2],\n",
    "      labels[:n_train], labels[n_train:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eb557e",
   "metadata": {},
   "source": [
    "### 4.4.4.4 高阶多项式函数拟合 (过拟合)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93733167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从多项式特征中选取所有维度\n",
    "train(poly_features[:n_train, :], poly_features[n_train:, :],\n",
    "      labels[:n_train], labels[n_train:], num_epochs=1500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
